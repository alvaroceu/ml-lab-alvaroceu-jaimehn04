{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 3: Jaime Héctor y Álvaro Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, es necesario realizar un preprocesamiento de los datos para garantizar que estén limpios, completos y en un formato adecuado que permita al modelo de machine learning aprender de manera eficiente. Para ello se deben evitar los valores nulos, normalizar las variables numéricas y codificar las variables categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cargar los datos en una variable\n",
    "datos_test = pd.read_csv(\"public_test.csv\")  # Fichero CSV con datos de test\n",
    "datos_train = pd.read_csv(\"public_train.csv\")  # Fichero CSV con datos de entrenamiento\n",
    "\n",
    "# Separar la información del resultado ovariable objetivo\n",
    "x_train = datos_train.drop(columns=\"ccs\")  # 'ccs' es la columna objetivo\n",
    "y_train = datos_train[\"ccs\"]\n",
    "x_test = datos_test\n",
    "\n",
    "# Iniciar transmormadores para adaptar los datos al modelo\n",
    "scaler = StandardScaler()\n",
    "numeric_imputer = SimpleImputer(strategy=\"mean\")  # Nulo numérico --> Media del resto\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")  # Nulo categórico --> Moda del resto\n",
    "oh_encoder = OneHotEncoder(sparse_output=False)  # One-hot encoding: Codificar variables categóricas\n",
    "\n",
    "# Transformador numérico (Eliminar nulos + normalizar)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", numeric_imputer),\n",
    "    (\"scaler\", scaler)\n",
    "])\n",
    "\n",
    "# Transformador categórico (Eliminar nulos + codificar)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", categorical_imputer),\n",
    "    (\"encoder\", oh_encoder)\n",
    "])\n",
    "\n",
    "# Agrupar las deiferentes columnas relevantes de los datos\n",
    "desc_columns = [col for col in x_train.columns if col.startswith('desc_')]\n",
    "fgp_columns = [col for col in x_train.columns if col.startswith('fgp_')]\n",
    "adduct_column = [\"adduct\"]  # 'adduct' es categórica \n",
    "\n",
    "# Transformar usando ColumnTransformer, para elegir a que columnas aplicar cada tipo de transformación\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, desc_columns + fgp_columns),  # Numéricos\n",
    "        (\"categorical\", categorical_transformer, adduct_column)  # Categóricos\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Aplicar los cambios realizados en los datos y mantenerlos como DataFrame\n",
    "def preprocess_data(x):\n",
    "    transformed = transformer.fit_transform(x)\n",
    "    return pd.DataFrame(transformed, index=x.index)\n",
    "\n",
    "x_train = preprocess_data(x_train)\n",
    "x_test = preprocess_data(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y estimación del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 1): 3.7602733086581424\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 1): 3.516498000000013\n",
      "Fold 2\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 2): 3.895107819362252\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 2): 3.453996999999987\n",
      "Fold 3\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 3): 3.8127746781627536\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 3): 3.3357790000000023\n",
      "Fold 4\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 4): 3.8553671912998624\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 4): 3.3449979999999755\n",
      "Fold 5\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 5): 3.837829234451391\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 5): 3.5383330000000086\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Dividir los datos: 70% entrenamiento, 15% validación, 15% test\n",
    "x_train_final, x_temp, y_train_final, y_temp = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "x_val, x_test_train, y_val, y_test_train = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Bucle interno para selección de hiperparámetros\n",
    "def fit_model(x_train_final, y_train_final, model):\n",
    "    inner_kfold = KFold(n_splits=5, shuffle = True,random_state=42)\n",
    "    maes = []\n",
    "    for train_indices, val_indices in inner_kfold.split(x_train_final):\n",
    "        x_train = x_train_final.iloc[train_indices]\n",
    "        y_train = y_train_final.iloc[train_indices]\n",
    "        x_val = x_train_final.iloc[val_indices]\n",
    "        y_val = y_train_final.iloc[val_indices]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        y_val_pred = model.predict(x_val)\n",
    "        maes.append(median_absolute_error(y_val, y_val_pred))\n",
    "\n",
    "    avg_mae = np.mean(maes)\n",
    "\n",
    "    return avg_mae\n",
    "\n",
    "# Modelos a comparar\n",
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Random Forest\", RandomForestRegressor(5))\n",
    "]\n",
    "\n",
    "# Bucle externo para validación cruzada\n",
    "outer_kfold = KFold(n_splits=5, shuffle = True ,random_state=42)\n",
    "results = []\n",
    "fold = 1\n",
    "for train_val_indices, test_indices in outer_kfold.split(x_train, y_train):\n",
    "    x_train_val = x_train.iloc[train_val_indices]\n",
    "    y_train_val = y_train.iloc[train_val_indices]\n",
    "    x_test_fold = x_train.iloc[test_indices]\n",
    "    y_test_fold = y_train.iloc[test_indices]\n",
    "\n",
    "    print(f\"Fold {fold}\")\n",
    "    for name, model in models:\n",
    "        print(f\"Evaluando modelo: {name}\")\n",
    "        avg_mae = fit_model(x_train_val, y_train_val, model)\n",
    "\n",
    "        model.fit(x_train_val, y_train_val)\n",
    "        y_test_pred = model.predict(x_test_fold)\n",
    "        mae_test = median_absolute_error(y_test_fold, y_test_pred)\n",
    "        print(f\"MAE en el conjunto  (Fold {fold}): {mae_test}\")\n",
    "\n",
    "        results.append((name, fold, avg_mae, mae_test))\n",
    "\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Separar los datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba interno)\n",
    "x_train_final, x_test_train, y_train_final, y_test_train = train_test_split(\n",
    "    x_train, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Separar el conjunto de entrenamiento en entrenamiento y validación (75% entrenamiento, 25% validación)\n",
    "x_train_final, x_val_train, y_train_final, y_val_train = train_test_split(\n",
    "    x_train_final, y_train_final, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos\n",
    "print(\"Dimensiones de los conjuntos:\")\n",
    "print(\"x_train_final:\", x_train_final.shape)\n",
    "print(\"x_val_train:\", x_val_train.shape)\n",
    "print(\"x_test_train:\", x_test_train.shape)\n",
    "\n",
    "# Crear y entrenar el modelo (Random Forest Regressor como ejemplo)\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "model.fit(x_train_final, y_train_final)\n",
    "\n",
    "# Predecir valores en los conjuntos de validación y prueba interno\n",
    "y_val_pred = model.predict(x_val_train)\n",
    "y_test_pred = model.predict(x_test_train)\n",
    "\n",
    "# Calcular el MAE para validación y prueba interno\n",
    "mae_val = mean_absolute_error(y_val_train, y_val_pred)\n",
    "mae_test = mean_absolute_error(y_test_train, y_test_pred)\n",
    "\n",
    "print(\"MAE en conjunto de validación:\", mae_val)\n",
    "print(\"MAE en conjunto de prueba interno:\", mae_test)\n",
    "\n",
    "# Si el modelo tiene buen rendimiento, aplicarlo al conjunto de prueba real\n",
    "final_predictions = model.predict(x_test)\n",
    "\n",
    "# Guardar las predicciones en un archivo CSV\n",
    "import pandas as pd\n",
    "output = pd.DataFrame(final_predictions, columns=[\"ccs_pred\"])\n",
    "output.to_csv(\"test_preds.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 3: Jaime Héctor y Álvaro Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, es necesario realizar un preprocesamiento de los datos para garantizar que estén limpios, completos y en un formato adecuado que permita al modelo de machine learning aprender de manera eficiente. Para ello se deben evitar los valores nulos, normalizar las variables numéricas y codificar las variables categóricas. Además, se observa que los datos aportados en public_test.csv son demasiado grandes, lo que puede causar sobreajuste. Para evitar esto reduciremos el número de columnas desc y fgp a un número más razonable (esto también hará al modelo más veloz). Por último haremos que las columnas de los diferentes adcutos tengan más peso multiplicando por un factor de 10, ya que el tipo de aducto es esencial a la hora de predecir la collision cross section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cargar los datos en una variable\n",
    "datos_test = pd.read_csv(\"public_test.csv\")  # Fichero CSV con datos de test\n",
    "datos_train = pd.read_csv(\"public_train.csv\")  # Fichero CSV con datos de entrenamiento\n",
    "\n",
    "# Separar la información del resultado o variable objetivo\n",
    "x_train = datos_train.drop(columns=\"ccs\")  # 'ccs' es la columna objetivo\n",
    "y_train = datos_train[\"ccs\"]\n",
    "x_test = datos_test\n",
    "\n",
    "# Iniciar transformadores para adaptar los datos al modelo\n",
    "scaler = StandardScaler()\n",
    "numeric_imputer = SimpleImputer(strategy=\"mean\")  # Nulo numérico --> Media del resto\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")  # Nulo categórico --> Moda del resto\n",
    "oh_encoder = OneHotEncoder(sparse_output=False)  # One-hot encoding: Codificar variables categóricas\n",
    "\n",
    "# Transformador numérico (Eliminar nulos + normalizar)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", numeric_imputer),\n",
    "    (\"scaler\", scaler)\n",
    "])\n",
    "\n",
    "# Transformador categórico (Eliminar nulos + codificar)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", categorical_imputer),\n",
    "    (\"encoder\", oh_encoder)\n",
    "])\n",
    "\n",
    "# Agrupar las diferentes columnas relevantes de los datos\n",
    "desc_columns = [col for col in x_train.columns if col.startswith('desc_')]\n",
    "fgp_columns = [col for col in x_train.columns if col.startswith('fgp_')]\n",
    "adduct_column = [\"adduct\"]  # 'adduct' es categórica\n",
    "\n",
    "# Reducir la dimensionalidad de las columnas desc y fgp para que 'adduct' tenga más peso relativo\n",
    "reduced_desc_columns = desc_columns[:500]  # Seleccionamos las primeras 500 columnas\n",
    "reduced_fgp_columns = fgp_columns[:300]  # Seleccionamos las primeras 300 columnas\n",
    "\n",
    "# Transformar usando ColumnTransformer, para elegir a qué columnas aplicar cada tipo de transformación\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numeric\", numeric_transformer, reduced_desc_columns + reduced_fgp_columns),  # Numéricos seleccionados\n",
    "        (\"categorical\", categorical_transformer, adduct_column)  # Categóricos\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Aplicar los cambios realizados en los datos (no los resultados)\n",
    "transformer = transformer.set_output(transform=\"pandas\")\n",
    "x_train = transformer.fit_transform(x_train)\n",
    "x_test = transformer.transform(x_test)\n",
    "\n",
    "# Aumentar el peso de las columnas del one-hot encoding de 'adduct' multiplicando por un factor para aumentar su influencia \n",
    "adduct_encoded_columns = [col for col in x_train.columns if \"adduct\" in col]\n",
    "x_train[adduct_encoded_columns] *= 20  # Factor = 20\n",
    "x_test[adduct_encoded_columns] *= 20  # Factor = 20\n",
    "\n",
    "# Evitar la existencia de valores nulos\n",
    "assert x_train.isnull().sum().sum() == 0, \"Valores nulos encontrados en x_train tras el preprocesamiento\"\n",
    "assert x_test.isnull().sum().sum() == 0, \"Valores nulos encontrados en x_test tras el preprocesamiento\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y estimación del error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a comprobar en primer lugar el error estimado al utilizar un modelo de Regresión Lineal con los datos que han sido preparados en la sección anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para Regresión lineal se obtiene una mediana de error: 3.6065857479507315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "# Dividir los datos: 80% entrenamiento, 20% validación\n",
    "x_train_final, x_val, y_train_final, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "model1 = LinearRegression()\n",
    "\n",
    "model1.fit(x_train_final, y_train_final)\n",
    "\n",
    "y_val_pred1 = model1.predict(x_val)\n",
    "mae_val = median_absolute_error(y_val, y_val_pred1)\n",
    "    \n",
    "print(f\"Para Regresión lineal se obtiene una mediana de error: {mae_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora calculamos la estimación con un Random Forest de 50 estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para Random Forest con 50 estimadores se obtiene una mediana de error: 2.771891320238069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model2 = RandomForestRegressor(50)\n",
    "\n",
    "model2.fit(x_train_final, y_train_final)\n",
    "\n",
    "y_val_pred2 = model2.predict(x_val)\n",
    "mae_val = median_absolute_error(y_val, y_val_pred2)\n",
    "    \n",
    "print(f\"Para Random Forest con 50 estimadores se obtiene una mediana de error: {mae_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, calculamos la estimación con un Random Forest de 100 estimadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para Random Forest con 100 estimadores se obtiene una mediana de error: 2.804172477499918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model3 = RandomForestRegressor(100)\n",
    "\n",
    "model3.fit(x_train_final, y_train_final)\n",
    "\n",
    "y_val_pred3 = model3.predict(x_val)\n",
    "mae_val = median_absolute_error(y_val, y_val_pred3)\n",
    "    \n",
    "print(f\"Para Random Forest con 100 estimadores se obtiene una mediana de error: {mae_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que las estimaciones anteriores han sido directamente sobre el conjuto de datos preprocesados vamos a hacer un estudio más modular. Para asegurarnos de que los resultados obtenidos son fiables utilizamos Validación Cruzada 5-Fold para el caso de Regresión Lineal y Random Forest de 50 estimadores (el de 100 estimadores no lo hacemos para ahorrar tiempo) de forma que realizaremos las estimaciones sobre diferentes subconjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 1): 3.6234851140346365\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 1): 2.884834199999972\n",
      "Fold 2\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 2): 3.7592405202171335\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 2): 3.024603774999875\n",
      "Fold 3\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 3): 3.5385551469926213\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 3): 2.745407020238112\n",
      "Fold 4\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 4): 3.6566890015071465\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 4): 2.780458363333352\n",
      "Fold 5\n",
      "Evaluando modelo: Linear Regression\n",
      "MAE en el conjunto  (Fold 5): 3.3873314848351015\n",
      "Evaluando modelo: Random Forest\n",
      "MAE en el conjunto  (Fold 5): 2.9027976499999824\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Dividir los datos: 70% entrenamiento, 15% validación, 15% test\n",
    "x_train_final, x_temp, y_train_final, y_temp = train_test_split(x_train, y_train, test_size=0.3, random_state=42)\n",
    "x_val, x_test_train, y_val, y_test_train = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Bucle interno de la validación cruzada\n",
    "def fit_model(x_train_final, y_train_final, model):\n",
    "    inner_kfold = KFold(n_splits=5, shuffle = True,random_state=42)\n",
    "\n",
    "    for train_indices, val_indices in inner_kfold.split(x_train_final):\n",
    "        x_train = x_train_final.iloc[train_indices]\n",
    "        y_train = y_train_final.iloc[train_indices]\n",
    "        x_val = x_train_final.iloc[val_indices]\n",
    "        y_val = y_train_final.iloc[val_indices]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Modelos a comparar\n",
    "models = [\n",
    "    (\"Linear Regression\", LinearRegression()),\n",
    "    (\"Random Forest\", RandomForestRegressor(50))\n",
    "]\n",
    "\n",
    "# Bucle externo para validación cruzada\n",
    "outer_kfold = KFold(n_splits=5, shuffle = True ,random_state=42)\n",
    "\n",
    "fold = 1\n",
    "for train_val_indices, test_indices in outer_kfold.split(x_train, y_train):\n",
    "    x_train_val = x_train.iloc[train_val_indices]\n",
    "    y_train_val = y_train.iloc[train_val_indices]\n",
    "    x_test_fold = x_train.iloc[test_indices]\n",
    "    y_test_fold = y_train.iloc[test_indices]\n",
    "\n",
    "    print(f\"Fold {fold}\")\n",
    "    for name, model in models:\n",
    "        print(f\"Evaluando modelo: {name}\")\n",
    "        model = fit_model(x_train_val, y_train_val, model)\n",
    "\n",
    "        y_test_pred = model.predict(x_test_fold)\n",
    "        mae_test = median_absolute_error(y_test_fold, y_test_pred)\n",
    "        print(f\"MEDAE en el conjunto  (Fold {fold}): {mae_test}\")\n",
    "\n",
    "    fold += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si realizamos la media de estos valores obtenemos: 3.59% para el modelo de Regresión Lineal y 2.86% para el modelo Random Forest. Debido a que con la validación cruzada se realizan más comprobaciones con diferentes subconjuntos de datos y estamos obteniendo valores muy similares a los casos simples (3.6% y 2.77% sin validación cruzada) podemos determinar que el modelo funciona de forma equilibrada y constante, y que no presenta comportamientos distintos frente a subconjuntos de datos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto que usando Random Forest de 50 estimadores obtenemos los mejores resultados segun la MEDAE (venciendo al modelo de regresión lineal y al random forest de 100 estimadores), utilizaremos este modelo para las predicciones finales (pero esta vez sin dividir los datos en entrenamiento y validación, sino usando directamente las columnas seleccionadas tras el preprocesamiento). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento con todos los datos\n",
    "model2.fit(x_train, y_train)\n",
    "\n",
    "#Predicciones del conjunto test\n",
    "y_pred = model2.predict(x_test)\n",
    "\n",
    "#Creación del csv sin cabecera\n",
    "df_resultados = pd.DataFrame(y_pred)\n",
    "df_resultados.to_csv('test_preds.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si analizamos el desempeño de los diferentes modelos vemos que la Regresión Lineal es un modelo funcional básico, pero presenta peor rendimiento que el Random Forest.\n",
    "\n",
    "Se observa que el Random Forest con 50 estimadores devuelve los mejores resultados, superando incluso al modelo con 100 estimadores. Esto ocurre ya que, aunque aumentar el número de estimadores permite que el modelo pueda establecer relaciones más complejas mediante exploraciones más profundas, también aumenta el riesgo de sufrir overfitting y de adaptarse a irregularidades de los datos, lo cual empeora las predicciones futuras.\n",
    "\n",
    "Además, al evaluar los resultados obtenidos tras utilizar validación cruzada detectamos un error medio prácticamente idéntico al de los entrenamientos iniciales, y puesto que la validación cruzada evalúa el modelo en diferentes subconjuntos de datos tratando de evitar resultados imprecisos por configuraciones concretas de los datos de entrenamiento, nos aseguramos de que efectivamente los modelos estaba funcionando de forma correcta desde un principio.\n",
    "\n",
    "Es necesario tener en cuenta que estos resultados dependen en gran medida de los modelos utilizados y sus diferentes parámetros, así cómo de los datos utilizados y su correcto preprocesamiento para mejorar la eficiencia de los modelos.\n",
    "\n",
    "\n",
    "\n",
    "Los porcentajes de error obtenidos (2.7% - 3.6%) son más altos de lo esperado. Esto indica que podrían realizarse más mejores complejas para reducir estos errores, aunque esto supondría un nivel de procesamiento de datos muy superior. Alguna de estas mejoras podrían ser:\n",
    "\n",
    "-Mejor optimización de hiperparámetros realizando comprobaciones más exhaustivas en la validación cruzada\n",
    "\n",
    "-Utilización de modelos más complejos\n",
    "\n",
    "-Ingeniería de características más avanzada generando nuevas variables como resultado de transformaciones de las actuales tratando de tener un conjunto de datos más reducido pero igual de efectivo\n",
    "\n",
    "-Aumentar la dimensionalidad del modelo exigiendo exploraciones más profundas o con más bucles\n",
    "\n",
    "\n",
    "\n",
    "Además de lo documentado en este archivo, hemos tratado de emplear sistemas más complejos para abordar el problema cómo el uso de redes neuronales y el uso de estrategias cómo boosting y stacking, no obstante, de esta forma obtuvimos peores resultados (alrededor del 6%) por lo que decidimos mantener soluciones más sencillas pero aparentemente más eficaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
